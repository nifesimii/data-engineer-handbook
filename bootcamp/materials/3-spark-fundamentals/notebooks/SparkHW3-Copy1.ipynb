{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b48d10-7ddc-4d74-ad45-e1b033849cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/15 01:43:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, col,split,lit,broadcast\n",
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Jupyter\").getOrCreate()\n",
    "\n",
    "# Disable broadcast joins\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "#for SPJ to be enabled it should have minimal of these 2 configs set:\n",
    "# Setting SPJ related configs\n",
    "spark.conf.set('spark.sql.sources.v2.bucketing.enabled','true') \n",
    "spark.conf.set('spark.sql.sources.v2.bucketing.pushPartValues.enabled','true')\n",
    "spark.conf.set('spark.sql.iceberg.planning.preserve-data-grouping','true')\n",
    "spark.conf.set('spark.sql.requireAllClusterKeysForCoPartition','false')\n",
    "spark.conf.set('spark.sql.sources.v2.bucketing.partiallyClusteredDistribution.enabled','true')\n",
    "\n",
    "\n",
    "\n",
    "# Read the match_details CSV file\n",
    "match_details = spark.read.option(\"header\", \"true\").csv(\"/home/iceberg/data/match_details.csv\")\n",
    "\n",
    "# Read the match CSV file\n",
    "matches = spark.read.option(\"header\", \"true\").csv(\"/home/iceberg/data/matches.csv\")\n",
    "\n",
    "# Read the medals_matches_players CSV file\n",
    "medals_matches_players = spark.read.option(\"header\", \"true\").csv(\"/home/iceberg/data/medals_matches_players.csv\")\n",
    "\n",
    "# Read the medals CSV file\n",
    "medals = spark.read.option(\"header\", \"true\").csv(\"/home/iceberg/data/medals.csv\")\n",
    "\n",
    "\n",
    "# Read the maps CSV file\n",
    "maps = spark.read.option(\"header\", \"true\").csv(\"/home/iceberg/data/maps.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f379a1d-7ef7-4ea5-825b-cd800f5b7ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Bootcamp Database\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS bootcamp\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51fb7a6-3023-47e5-9073-4b80852bca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dropping the match_details if exists schema \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS bootcamp.match_details\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d1dfdb-b6eb-4d6b-93d0-e3b734eb063b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the match_details schema \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.match_details (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     player_total_kills INTEGER,\n",
    "     player_total_deaths INTEGER\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (bucket(16, match_id))\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5985cebd-8478-48cb-be05-b5ea76364b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match details records count : 151761\n"
     ]
    }
   ],
   "source": [
    "#Writing the match_details data into the match_details spark table \n",
    "\n",
    "match_details.select(\"match_id\", \"player_gamertag\",\"player_total_kills\", \"player_total_deaths\") \\\n",
    ".write.mode(\"overwrite\") \\\n",
    ".bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details\") \n",
    "  \n",
    "\n",
    "print(f\"Match details records count : {match_details.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65fa85c1-957f-4ca2-89c7-2c82fa61b6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dropping the matches schema \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS bootcamp.matches\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c83ed6d-6f39-4f7f-b963-17424df7a33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the medals schema \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.matches (\n",
    "        match_id STRING,\n",
    "        mapid STRING,\n",
    "        is_team_game STRING,\n",
    "        playlist_id STRING,\n",
    "        completion_date TIMESTAMP\n",
    "  )\n",
    "   USING iceberg\n",
    "   PARTITIONED BY (bucket(16, match_id))\n",
    "   \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e37465-cce0-446f-8ac0-3f1e5b638eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches records count : 24025\n"
     ]
    }
   ],
   "source": [
    "#Writing the matches data into the matches spark table \n",
    "\n",
    "matches.select(\"match_id\", \"mapid\", \"is_team_game\", \"is_match_over\", \"playlist_id\", \"completion_date\") \\\n",
    ".write.mode(\"overwrite\") \\\n",
    ".bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.matches\") \n",
    "  \n",
    "\n",
    "print(f\"Matches records count : {matches.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22475c78-0822-40ae-a2e5-583082bf90f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dropping the medals_matches_players schema \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS bootcamp.medals_matches_players\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52030a9-c355-41ed-ae63-b11e15a65518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the medals_matches_players schema \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.medals_matches_players (\n",
    "        match_id STRING,\n",
    "        player_gamertag STRING,\n",
    "        medal_id STRING,\n",
    "        count INTEGER\n",
    "  )\n",
    "   USING iceberg\n",
    "   PARTITIONED BY (bucket(16, match_id));\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883cd222-227c-42b2-b1fc-d49e098d9764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medals Match Player details records count : 755229\n"
     ]
    }
   ],
   "source": [
    "# Writing into the  medals_matches_players Schema\n",
    "medals_matches_players.select(\"match_id\", \"player_gamertag\",\"medal_id\", \"count\",) \\\n",
    "     .write.mode(\"overwrite\") \\\n",
    "     .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.medals_matches_players\") \n",
    "\n",
    "print(f\"Medals Match Player details records count : {medals_matches_players.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881d5dd7-c01e-416e-8b58-fbf5b26ba808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Medals DataFrame as a table\n",
    "medals.write.mode(\"overwrite\").saveAsTable(\"bootcamp.medals\")\n",
    "# medals.createOrReplaceTempView(\"bootcamp.medals\")\n",
    "\n",
    "# Save the Maps DataFrame as a table\n",
    "maps.write.mode(\"overwrite\").saveAsTable(\"bootcamp.maps\")\n",
    "# maps.createOrReplaceTempView(\"bootcamp.maps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a6449b-3042-48e0-8b2a-2be0833151f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Bucket join and broadcast join to get merged aggregate data frame to answer questions\n",
    "spark.table(\"bootcamp.matches\").alias(\"mtc\") \\\n",
    ".join(spark.table(\"bootcamp.match_details\").alias(\"mth_det\"), col(\"mtc.match_id\") == col(\"mth_det.match_id\"), \"left\") \\\n",
    ".join(spark.table(\"bootcamp.medals_matches_players\").alias(\"medals_mth_players\"), ((col(\"mtc.match_id\") == col(\"medals_mth_players.match_id\")) &\n",
    "(col(\"mth_det.player_gamertag\") == col(\"medals_mth_players.player_gamertag\"))), \"left\") \\\n",
    ".join(broadcast(spark.table(\"bootcamp.medals\")).alias(\"medls\"), col(\"medals_mth_players.medal_id\") == col(\"medls.medal_id\"), \"inner\") \\\n",
    ".join(broadcast(spark.table(\"bootcamp.maps\")).alias(\"mps\"), col(\"mtc.mapid\") == col(\"mps.mapid\"), \"inner\") \\\n",
    ".select(col(\"mtc.match_id\"),col(\"mtc.mapid\"),col(\"mps.name\").alias(\"map_name\"),col(\"medals_mth_players.medal_id\"),\n",
    "col(\"medls.name\").alias(\"medal_name\"),col(\"mtc.playlist_id\"),col(\"mtc.completion_date\"), \\\n",
    "col(\"mth_det.player_gamertag\"), col(\"classification\"), col(\"mth_det.player_total_kills\"),col(\"medals_mth_players.count\")).write.mode(\"overwrite\").saveAsTable(\"bootcamp.final_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdbcf21d-44a0-4ae0-81bf-6ef56c6f6354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[match_id: string, mapid: string, map_name: string, medal_id: string, medal_name: string, playlist_id: string, completion_date: string, player_gamertag: string, classification: string, player_total_kills: string, count: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the final aggregated merged data\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "select * from bootcamp.final_data\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22ae9e3e-cd04-42ab-a66b-18355fb9abe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[player_gamertag: string, match_id: string, kills: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question: Which player averages the most kills per game?\n",
    "# Query- Answer\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT player_gamertag, match_id, Avg(player_total_kills) AS kills\n",
    "FROM bootcamp.final_data\n",
    "GROUP BY player_gamertag, match_id\n",
    "ORDER BY kills DESC\n",
    "LIMIT(1)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c50565d-c42e-44ae-a131-e80741dfc090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[playlist_id: string, count: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question: Which playlist gets played the most?\n",
    "# Query- Answer\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT playlist_id, COUNT(Distinct match_id) AS count\n",
    "FROM bootcamp.final_data\n",
    "GROUP BY playlist_id\n",
    "ORDER BY count DESC\n",
    "LIMIT(1)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fefeb94e-2ad1-459a-aa43-1c3e8d0f85a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[map_name: string, count: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question: Which map gets played the most?\n",
    "# Query- Answer\n",
    "\n",
    "spark.sql(\"\"\" \n",
    "SELECT map_name,count(distinct match_id) AS count\n",
    "FROM bootcamp.final_data\n",
    "GROUP BY map_name\n",
    "ORDER BY count DESC\n",
    "LIMIT(1)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0df565c3-6469-444c-bced-0bbb75338cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[map_name: string, count: double]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question: Which map do players get the most Killing Spree medals on?\n",
    "# Query- Answer\n",
    "\n",
    "spark.sql(\"\"\"   \n",
    "SELECT map_name,Sum(Count) AS count\n",
    "FROM bootcamp.final_data\n",
    "WHERE classification = \"KillingSpree\"\n",
    "GROUP BY map_name\n",
    "ORDER BY count DESC\n",
    "LIMIT(1)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe1346ab-8d43-4d24-8692-bfc8107ec604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the final data back into dataframe\n",
    "final_df = spark.read.table(\"bootcamp.final_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3eae01d-a4b4-4df8-9c6c-3156ac19393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [playlist_id#824 ASC NULLS FIRST, map_name#821 ASC NULLS FIRST, match_id#819 ASC NULLS FIRST], false, 0\n",
      "   +- Exchange hashpartitioning(match_id#819, 5), REPARTITION_BY_NUM, [plan_id=666]\n",
      "      +- BatchScan demo.bootcamp.final_data[match_id#819, mapid#820, map_name#821, medal_id#822, medal_name#823, playlist_id#824, completion_date#825, player_gamertag#826, classification#827, player_total_kills#828, count#829] demo.bootcamp.final_data (branch=null) [filters=, groupedBy=] RuntimeFilters: []\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [playlist_id#824 ASC NULLS FIRST, map_name#821 ASC NULLS FIRST, match_id#819 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(playlist_id#824 ASC NULLS FIRST, map_name#821 ASC NULLS FIRST, match_id#819 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=681]\n",
      "      +- Exchange hashpartitioning(match_id#819, 5), REPARTITION_BY_NUM, [plan_id=678]\n",
      "         +- BatchScan demo.bootcamp.final_data[match_id#819, mapid#820, map_name#821, medal_id#822, medal_name#823, playlist_id#824, completion_date#825, player_gamertag#826, classification#827, player_total_kills#828, count#829] demo.bootcamp.final_data (branch=null) [filters=, groupedBy=] RuntimeFilters: []\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##Trying different partition columns and number to see which has the smallest data size\n",
    "\n",
    "#local partition sort\n",
    "sorted = final_df.repartition(5, col(\"match_id\")) \\\n",
    "                .sortWithinPartitions(col(\"playlist_id\"),col(\"map_name\"),col(\"match_id\"))\n",
    "\n",
    "\n",
    "#global sort \n",
    "unsorted = final_df.repartition(5, col(\"match_id\")) \\\n",
    "            .sort(col(\"playlist_id\"),col(\"map_name\"),col(\"match_id\"))\n",
    "\n",
    "\n",
    "# sorted.show(5)\n",
    "# unsorted.show(5)\n",
    "sorted.explain()\n",
    "unsorted.explain()\n",
    "\n",
    "sorted.write.mode(\"overwrite\").saveAsTable(\"bootcamp.finaldf_sorted\")\n",
    "unsorted.write.mode(\"overwrite\").saveAsTable(\"bootcamp.finaldf_unsorted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c79712d7-2cd5-462e-a471-9776b491e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[size: bigint, num_files: bigint, sorted: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT SUM(file_size_in_bytes) as size, COUNT(1) as num_files, 'sorted' \n",
    "FROM demo.bootcamp.finaldf_sorted.files\n",
    "\n",
    "UNION ALL\n",
    "SELECT SUM(file_size_in_bytes) as size, COUNT(1) as num_files, 'unsorted' \n",
    "FROM demo.bootcamp.finaldf_unsorted.files\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4324690-5ba9-4fe8-87f1-fec119c49005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
